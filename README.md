# Тестовое задание:
![image](https://github.com/user-attachments/assets/2b711c7f-dde9-4b13-89e0-17a6525c0d58)

Я оставлял некоторые пометки в коде, но в основном предполагаю отслеживание рабочего процесса по этому README файлу. Старался писать подробно, так как: с k8s знаком в рамках теории и небольшого взаимодействия с minikube. 
Работаю с легковесной виртуалкой kubectl+minikube, так что если и буду тестировать, то, очевидно, не на 5 нодах и с зонами не поразбираться.

# Процесс работы:
1. Создал репозиторий с yaml файлом и .md описанием, работаю в vscode с расширением, так что сгенерил шаблон. Пока что деплоймент+сервис, но нужно будет еще смотреть в сторону скейлеров.
![image](https://github.com/user-attachments/assets/40487b15-0f90-4aea-957c-1dab6bfd7b45)

2. "по результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой", пока что в деплойменте поставлю просто 4 реплики и rollingUpdate стратегию с минимальными параметрами
![image](https://github.com/user-attachments/assets/258ff437-a53b-4275-ab02-af95f36c7140)

3. "на первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. По памяти всегда “ровно” в районе 128M memory" и "хотим минимального потребления ресурсов от этого deployment’а".
Это настраивается через template.spec.containers.resources, про память понятно, а для процессора нужно немного подумать и погуглить. Из того, что я понял, нужно настроить requests с учетом стартового всплеска, допустим в 2 раза больше обычного. Также настраиваются лимиты, однако их советуют выставлять не сильно больше, чтобы общее распределенное поведение сохранялось.
Не совсем понятно, лучшая ли это идея, возможно есть какие-то способы "поумнее", а может из-за маленьких requests всё вообще упадет, не успев адаптироваться.

![image](https://github.com/user-attachments/assets/10625d81-3a82-44be-afb7-7c6fec5ad590)

4. "приложение требует около 5-10 секунд для инициализации". Это пункт про работу с пробами, с ними я знаком, поэтому просто настрою как считаю правильным. Также поставил какой-то порт для контейнера, и, так как это веб-приложение по условию, будем проверять через httpGet.

![image](https://github.com/user-attachments/assets/2d563b9b-9a34-4899-a6c6-8c85b6798012)

5. также подредактировал service, пока что так

![image](https://github.com/user-attachments/assets/eaf8cdd2-b440-4bd6-bcc7-65e08435493c)

6. "хотим максимально отказоустойчивый deployment" и "у нас мультизональный кластер (три зоны), в котором пять нод".
Так, ну в моем представлении нужно поработать с podaffinity, чтобы нам при возможном последующем скейлинге реплик (ну, до 6+) не закидывало эти же поды на одинаковые ноды, и это даже не совсем про отказоустойчивость. Но главное надо разобраться с зонами, с которыми я еще не работал, на самом деле я не совсем уверен, что нужно что-то явно указывать, посмотрим.
Про первую часть того, что я написал, первоначально я бы сделал так:
![image](https://github.com/user-attachments/assets/476b7718-0434-4f11-8d42-6376084b112c)

Теперь нужно ознакомиться с работой с мультизональным кластером и посмотреть примеры. 
Нашел в доке вот такую штуку: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
Почитал, что, на самом деле, при использовании подобных ограничений то, что я сделал раньше, не особо имеет смысла. В плане, что topologySpreadConstraints итак об этом позаботится. В целом, как я понял, лучше либо смягчить antiAffinity через weight, либо сделать не "required" а "preferred", а может все вместе. Нужно тестировать по-хорошему.
А что касается topologySpreadConstraints, то я настроил вот так:
![image](https://github.com/user-attachments/assets/85c6188b-dfcd-426e-b26d-bc5778059e10)

Affinity подредактировал, все равно опечатался в синтаксисе изначально.
![image](https://github.com/user-attachments/assets/7e023adb-a669-4bfe-ac85-765648b2b8c5)


7. Последнее, что осталось, это поработать со скейлингом, deployment и service вроде бы готовы к тестовому запуску. Так вот, вспоминаем, что нагрузка по условию неравномерная, и нам нужно учесть, что "приложение имеет дневной цикл по нагрузке – ночью запросов на порядки меньше, пик – днём", и мы "хотим минимального потребления ресурсов от этого deployment’а".
Из того, что я знаю, просто поработаем с https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ сущностью. Подсматривал тут https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/

Базово выглядит вот так
![image](https://github.com/user-attachments/assets/8aa3bb74-2e07-43ba-ab34-29fa7994a21d)

Осталось разобраться согласно каким метрикам оно будет скейлить. По памяти нет, нагрузка постоянная. Неплохой вариант смотреть по нагрузке на процессор, хотя я и предполагаю, что не совсем правильно выделил ресурсы. В документации приведено много разных вариантов, даже те же requests-per-second и комбинация из всего сразу.
В общем, попробую по процессору. Буду исходить из логики, что стандартная нагрузка на процессор, по условию, 0.1 и если она начнет расти, нам нужно добавлять поды. Так, если указать averageUtilization: 70, то при 0.14 будет добавляться реплика. Опять же, не до конца уверен в правильности работы с ресурсами, нужно смотреть. Вообще, я почитал, что скейлер не будет масштабироваться мгновенно, поэтому стартовую ситуацию с большой нагрузкой он должен обрабатывать нормально.

![image](https://github.com/user-attachments/assets/316fd576-2f4a-4132-9280-04a2ab747855)


8. Попробую просто запустить и посмотреть как оно отработает во избежание глупых ошибок. Проверю просто на ненастроенном образе nginx, посмотрим что получится.

![image](https://github.com/user-attachments/assets/d99e050c-9d8f-43d6-82fa-afccb50f2868)

Убрал пробы. Добавил некоторое поведение скейлеру, чтобы посмотреть на скейлинг и может попробовать посимулировать нагрузку

![image](https://github.com/user-attachments/assets/87ae095d-3aeb-49ed-84d4-62dc43159e3f)

При простое деплоймент заскейлился до 2ух подов. Вспоминаю, что не зря изменил affinity required на preferred, можно потестировать на одной ноде. Использовал аддон metrics-server миникуба.

![image](https://github.com/user-attachments/assets/69c81598-1f34-4e19-b264-82070fe97ae0)


В общем, посмотрел как можно симулировать нагрузку, нашел k6, попробовал, допробовался так что виртуалку себе положил :)
Из проблем выяснил то, что грузит оно всю ноду и наш скейлер не то чтобы реагирует. Особенно если учесть, что оно не смотрит на кратковременные нагрузки.
В целом, наверное не буду до конца адаптировать не особо предназначенный для этого инструмент и пытаться грузить бедный базовый nginx. Этот небольшой эксперимент положил рядом в other/, чтобы не путать.
